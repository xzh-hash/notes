java基础:

BigDecimal常用方法详解

add(BigDecimal):BigDecimal对象中的值相加，返回BigDecimal对象
subtract(BigDecimal):BigDecimal对象中的值相减，返回BigDecimal对象
multiply(BigDecimal):BigDecimal对象中的值相乘，返回BigDecimal对象
divide(BigDecimal):BigDecimal对象中的值相除，返回BigDecimal对象

抽象类 VS 接口

（1）抽象类的特点

1.抽象类由abstract修饰；
2.抽象类中允许出现抽象方法（也可以没有）；
3.抽象类不能通过构造器直接实例化；
4.可以在抽象类中定义普通方法供子类继承；
5.一个类如果有抽象方法，则该类必须定义为抽象类；

（2）接口（interface）
1.由final修饰的常量（可以没有）和公共的抽象（abstract）方法组成；
2.接口中的属性都是常量，即使定义时不添加public static final 修饰符，系统也会自动加上；
3.接口中的方法都是抽象方法，即使定义时不添加public abstract修饰符，系统也会自动加上；
4.接口不能被实例化，也不允许有构造方法；
5.一个类可以实现一个或多个接口，但只能继承一个父类；
6.继承父类和实现接口共存时,必须先继承后实现，即extends关键字必须在implements关键字前。

静态方法为什么不能调用非静态成员?
这个需要结合 JVM 的相关知识，主要原因如下：
1.静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。
2.在类的非静态成员不存在的时候静态方法就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。



遇到方法重载的情况怎么办呢？会优先匹配固定参数还是可变参数的方法呢？

答案是会优先匹配固定参数的方法，因为固定参数的方法匹配度更高。

拦截器和过滤器的区别

1.实现原理不同:
过滤器和拦截器 底层实现方式大不相同，过滤器 是基于函数回调的，拦截器 则是基于Java的反射机制（动态代理）实现的。
在我们自定义的过滤器中都会实现一个 doFilter()方法，这个方法有一个FilterChain 参数，而实际上它是一个回调接口。ApplicationFilterChain是它的实现类， 这个实现类内部也有一个 doFilter() 方法就是回调方法。
ApplicationFilterChain里面能拿到我们自定义的xxxFilter类，在其内部回调方法doFilter()里调用各个自定义xxxFilter过滤器，并执行 doFilter() 方法。
ApplicationFilterChain里面能拿到我们自定义的xxxFilter类，在其内部回调方法doFilter()里调用各个自定义xxxFilter过滤器，并执行 doFilter() 方法。

2.使用范围不同
我们看到过滤器 实现的是 javax.servlet.Filter 接口，而这个接口是在Servlet规范中定义的，也就是说过滤器Filter 的使用要依赖于Tomcat等容器，导致它只能在web程序中使用。
而拦截器(Interceptor) 它是一个Spring组件，并由Spring容器管理，并不依赖Tomcat等容器，是可以单独使用的。不仅能应用在web程序中，也可以用于Application、Swing等程序中。

3.触发时机不同
过滤器Filter是在请求进入容器后，但在进入servlet之前进行预处理，请求结束是在servlet处理完以后。

拦截器 Interceptor 是在请求进入servlet后，在进入Controller之前进行预处理的，Controller 中渲染了对应的视图之后请求结束。

4、拦截的请求范围不同
过滤器Filter执行了两次，拦截器Interceptor只执行了一次。这是因为过滤器几乎可以对所有进入容器的请求起作用，而拦截器只会对Controller中请求或访问static目录下的资源请求起作用。

5、注入Bean情况不同

6、控制执行顺序不同
过滤器用@Order注解控制执行顺序，通过@Order控制过滤器的级别，值越小级别越高越先执行;
拦截器默认的执行顺序，就是它的注册顺序，也可以通过Order手动设置控制，值越小越先执行。

①拦截器是基于Java的反射机制的，而过滤器是基于函数回调。
②拦截器不依赖与servlet容器，依赖于web框架，在SpringMVC中就是依赖于SpringMVC框架。过滤器依赖与servlet容器。
③拦截器只能对action（也就是controller）请求起作用，而过滤器则可以对几乎所有的请求起作用,并且可以对请求的资源进行起作用，但是缺点是一个过滤器实例只能在容器初始化时调用一次。
④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。
⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。
⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑

反射:
获取Class的三方式:
1.Class.forName(“完整类名带包名”)	静态方法
2.对象.getClass()	
3.类.class

通过反射实例化对象
  通过反射机制，获取Class，通过Class来实例化对象
  newInstance() 这个方法会调用User这个类的无参数构造方法，完成对象的创建。
  重点是：newInstance()调用的是无参构造，必须保证无参构造是存在的！
  
  Class c = Class.forName("javase.reflectBean.User");
  Object obj = c.newInstance();
	//获取所有的属性
   Field[] fields = studentClass.getDeclaredFields()
 // 获取no属性（根据属性的名称来获取Field）
     Field noField = studentClass.getDeclaredField("no");
     // 给obj对象(Student对象)的no属性赋值
     /*
            虽然使用了反射机制，但是三要素还是缺一不可：
                要素1：obj对象
                要素2：no属性
                要素3：22222值
         */
    noField.set(obj, 22222);

静态代理：
静态代理静态代理中，我们对目标对象的每个方法的增强都是手动完成的（后面会具体演示代码），非常不灵活（比如接口一旦新增加方法，目标对象和代理对象都要进行修改）且麻烦(需要对每个目标类都单独写一个代理类）
从 JVM 层面来说， 静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。

静态代理和动态代理的对比：
1.灵活性 ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！
2.JVM 层面 ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。

JDK 动态代理和 CGLIB 动态代理对比
1.JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。
2.就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。



JDK 动态代理机制
从 JVM 角度来说，动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。
在 Java 动态代理机制中 InvocationHandler 接口和 Proxy 类是核心。
Proxy 类中使用频率最高的方法是：newProxyInstance() ，这个方法主要用来生成一个代理对象。
 public static Object newProxyInstance(ClassLoader loader,
                                          Class<?>[] interfaces,
                                          InvocationHandler h)

1.loader :类加载器，用于加载代理对象。
2.interfaces : 被代理类实现的一些接口；
3.h : 实现了 InvocationHandler 接口的对象；

要实现动态代理的话，还必须需要实现InvocationHandler 来自定义处理逻辑。 当我们的动态代理对象调用一个方法时，这个方法的调用就会被转发到实现InvocationHandler 接口类的 invoke 方法来调用。
public interface InvocationHandler {

    /**
     * 当你使用代理对象调用方法的时候实际会调用到这个方法
     */
    public Object invoke(Object proxy, Method method, Object[] args)
        throws Throwable;
}

invoke() 方法有下面三个参数：
1.proxy :动态生成的代理类
2.method : 与代理类对象调用的方法相对应
3.args : 当前 method 方法的参数

JDK 动态代理类使用步骤：
1.定义一个接口及其实现类；
2.自定义 InvocationHandler 并重写invoke方法，在 invoke 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；
3.通过 Proxy.newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h) 方法创建代理对象；

CGLIB 动态代理机制
JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。

为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。
CGLIBopen in new window(Code Generation Library)是一个基于ASMopen in new window的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。CGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了CGLIBopen in new window， 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。

在 CGLIB 动态代理机制中 MethodInterceptor 接口和 Enhancer 类是核心。

CGLIB 动态代理类使用步骤
1.定义一个类；
2.自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；
3.通过 Enhancer 类的 create()创建代理类；

public class DebugMethodInterceptor implements MethodInterceptor {


    /**
     * @param o           被代理的对象（需要增强的对象）
     * @param method      被拦截的方法（需要增强的方法）
     * @param args        方法入参
     * @param methodProxy 用于调用原始方法
     */
    @Override
    public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
        //调用方法之前，我们可以添加自己的操作
        System.out.println("before method " + method.getName());
        Object object = methodProxy.invokeSuper(o, args);
        //调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method " + method.getName());
        return object;
    }

}


Redis

怎么保证缓存和数据库数据的一致性？



mysql


事务的实现:
1.事务的原子性是通过 undo log 来实现的
1.事务的持久性性是通过 redo log 来实现的
3.事务的隔离性是通过 (读写锁+MVCC)来实现的
而事务的终极大 boss 一致性是通过原子性，持久性，隔离性来实现的。

redo log:
redo log叫做重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中。

redo log有什么作用？
mysql为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Buffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。
那么问题来了，如果还没来的同步的时候宕机或断电了怎么办？还没来得及执行上面图中红色的操作。这样会导致丢部分已提交事务的修改信息！
所以引入了redo log来记录已成功提交事务的修改信息，并且会把redo log持久化到磁盘，系统重启之后在读取redo log恢复最新数据。
redo log是用来恢复数据的 用于保障，已提交事务的持久化特性。


undo log:
undo log 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。

undo log有什么作用？
undo log记录事务修改之前版本的数据信息，因此假如由于系统错误或者rollback操作而回滚的话可以根据undo log的信息来进行回滚到没被修改前的状态。
undo log是用来回滚数据的用于保障未提交事务的原子性。

mvcc
MVCC实现原理：mvcc的实现原理主要依赖于记录中的三个隐藏字段，undolog，read view来实现的。

1、隐藏字段：每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID，DB_ROLL_PTR，DB_ROW_ID等字段 
1),DB_TRX_ID：6字节，最近修改事务id，记录创建这条记录或者最后一次修改该记录的事务id。
2),DB_ROLl_PTR：7字节，回滚指针，指向这条记录的上一个版本，用于配合undolog，指向上一个旧版本 

1、Read View的可见性规则如下所示∶
首先要知道Read View中的三个全局属性∶
trx_list∶ 一个数值列表，用来维护Read View生成时刻系统正活跃的事务ID 
up_limt_id∶ 记录trx_list列表中事务ID最小的ID
low_limit_id∶ Read View生成时刻系统尚未分配的下一个事务ID。

2、具体的比较规则如下∶
1）、首先比较DB_TRX_ID<up_limit_id，如果小于，则当前事务能看到DB_TRX_ID所在的记录，如果大于等于进入下一个判断。
2）、接下来判断DB_TRX_ID>= low_limit_id，如果大于等于 则代表DB_TRX_ID所在的记录在Read View生成后才出现的，那么对于当前事务肯定不可见，如果小于，则进入下一步判断。
3）、判断DB_TRX_ID是否在活跃事务中，如果在，则代表在Read View生成时刻，这个事务还是活跃状态，还没有commit，修改的数据，当前 事务也是看不到，如果不在，则说明这个事务在Read View生成之前就已经开始commit，那么修改的结果是能够看见的。

nnoDB 和 MyISAM 的联系与区别

1.InnoDB 支持事务，MyISAM 不支持，对于 InnoDB 每一条 SQL 语句都默认封装成事务进行提交，这样就会影响速度，优化速度的方式是将多条 SQL 语句放在 begin 和 commit 之间，组成一个事务；
2.InnoDB 支持外键，而 MyISAM 不支持。
3.MyISAM 中 B+ 树的数据结构存储的内容是实际数据的地址值，它的索引和实际数据是分开的，只不过使用索引指向了实际数据。这种索引的模式被称为非聚集索引。
4.InnoDB 中 B+ 树的数据结构中存储的都是实际的数据，这种索引有被称为聚集索引。


索引 vs 辅助索引
1.InnoDB的主索引本身就是数据文件，因此主索引的data域保存的是数据文件本身；辅助索引的data域保存的是主键。
2.MyISAM的主索引和辅助索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。他们的data域保存的都只是数据文件的地址


自动生成的主键有什么问题？

1.使用不了主键索引，查询会进行全表扫描
2.影响数据插入性能，插入数据需要生成ROW_ID，而生成的ROW_ID是全局共享的（InnoDB 维护了一个全局的 dictsys.row_id，所有未定义主键的表都共享该row_id），并发会导致锁竞争，影响性能

1.索引优化
	1.创建索引一般为组合索引；
	2.组合索引的左前缀顺序优先选择有序的字段，避免随机io，其次优先选择选择性最高的字段
2.如果索引字段的长度过长，优化方案
	可以创建前缀索引或后缀索引

行级锁的使用有什么注意事项？
InnoDB 的行锁是针对索引字段加的锁，表级锁是针对非索引字段加的锁。当我们执行 UPDATE、DELETE 语句时，如果 WHERE条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。这个在我们日常工作开发中经常会遇到，一定要多多注意！！！

InnoDB 有哪几类行锁？
1.记录锁（Record Lock） ：也被称为记录锁，属于单个行记录上的锁。
2.间隙锁（Gap Lock） ：锁定一个范围，不包括记录本身。
3.临键锁（Next-Key Lock） ：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题（MySQL 事务部分提到过）。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁

在 InnoDB 默认的隔离级别 REPEATABLE-READ 下，行锁默认使用的是 Next-Key Lock。但是，如果操作的索引是唯一索引或主键，InnoDB 会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围


意向锁有什么作用？
如果需要用到表锁的话，如何判断表中的记录没有行锁呢，一行一行遍历肯定是不行，性能太差。我们需要用到一个叫做意向锁的东东来快速判断是否可以对某个表使用表锁。


MySQL整个查询的过程
• 客户端向 MySQL 服务器发送一条查询请求
• 服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段
• 服务器进行 SQL 解析、预处理、再由优化器生成对应的执行计划
• MySQL 根据执行计划，调用存储引擎的 API 来执行查询
• 将结果返回给客户端，同时缓存查询结果



spring

Spring 和 SpringBoot 的区别 ?

Spring Boot 基本上是 Spring 框架的扩展，它消除了设置 Spring 应用程序所需的 XML配置，为更快，更高效的开发生态系统铺平了道路。 以下是 Spring Boot 中的一些特点： 
1：创建独立的 spring 应用。 
2：嵌入 Tomcat , Jetty Undertow 而且不需要部署他们。 
3：提供的“starters” poms来简化 Maven 配置 
4：尽可能自动配置 spring 应用。 
5：提供生产指标,健壮检查和外部化配置 
6：绝对没有代码生成和 XML 配置要求

Spring常用注解
@Configuration把一个类作为一个IoC容器，它的某个方法头上如果注册了@Bean，就会作为这个Spring容器中的Bean。
@Scope注解 作用域
@Lazy(true) 表示延迟初始化
@Service用于标注业务层组件、
@Controller用于标注控制层组件（如struts中的action）
@Repository用于标注数据访问组件，即DAO组件。
@Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。
@Scope用于指定scope作用域的（用在类上）
@PostConstruct用于指定初始化方法（用在方法上）
@PreDestory用于指定销毁方法（用在方法上）
@DependsOn：定义Bean初始化及销毁时的顺序
@Primary：自动装配时当出现多个Bean候选者时，被注解为@Primary的Bean将作为首选者，否则将抛出异常
@Autowired 默认按类型装配，如果我们想使用按名称装配，可以结合@Qualifier注解一起使用。如下：
@Autowired @Qualifier(“personDaoBean”) 存在多个实例配合使用
@Resource默认按名称装配，当找不到与名称匹配的bean才会按类型装配。
@PostConstruct 初始化注解
@PreDestroy 摧毁注解 默认 单例 启动就加载
@Async异步方法调用


Spring Boot常用注解
1、@SpringBootApplication
替代 @SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan

2、@ImportAutoConfiguration
导入配置类，一般做测试的时候使用，正常优先使用@EnableAutoConfiguration 

3、@SpringBootConfiguration
替代@Configuration
SpringBootExceptionReporter的作用就是对启动过程的异常进行分析、报告
SpringBootBanner: 启动Spring的时候，启动日志会打印SpringBootBanner信息


Bean的生命周期 ：

1.实例化bean对象(通过构造方法或者工厂方法)
2.设置对象属性(setter等)（依赖注入）
3.如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的ID。（和下面的一条均属于检查Aware接口）
4.如果Bean实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身
5.将Bean实例传递给Bean的前置处理器的postProcessBeforeInitialization(Object bean, String beanname)方法
6.调用Bean的初始化方法
7.调用后置处理器postProcessAfterInitialization(Object bean, String beanname)方法
8.使用Bean
9.容器关闭之前，调用Bean的销毁方法



spring事务:
事务特性:
原子性（Atomicity）： 一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。
一致性（Consistency）： 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。
隔离性（Isolation）： 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。
持久性（Durability）: 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失

事务属性包含了 5 个方面：

隔离级别
传播行为:事务传播行为是为了解决业务层方法之间互相调用的事务问题
回滚规则
是否只读
事务超时

spring的 TransactionDefinition接口中一共定义了六种事务传播属性：
PROPAGATION_REQUIRED -- 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 
PROPAGATION_REQUIRES_NEW -- 新建事务，如果当前存在事务，把当前事务挂起。 
PROPAGATION_NESTED -- 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 
PROPAGATION_SUPPORTS -- 支持当前事务，如果当前没有事务，就以非事务方式执行。 
PROPAGATION_MANDATORY -- 支持当前事务，如果当前没有事务，就抛出异常。 
PROPAGATION_NOT_SUPPORTED -- 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 
PROPAGATION_NEVER -- 以非事务方式执行，如果当前存在事务，则抛出异常。 

@Transactional 的常用配置参数总结（只列出了 5 个我平时比较常用的）：
1.propagation	事务的传播行为，默认值为 REQUIRED，可选的值在上面介绍过
2.isolation	事务的隔离级别，默认值采用 DEFAULT，可选的值在上面介绍过
3.timeout	事务的超时时间，默认值为-1（不会超时）。如果超过该时间限制但事务还没有完成，则自动回滚事务。
4.readOnly	指定事务是否为只读事务，默认值为 false。
5.rollbackFor	用于指定能够触发事务回滚的异常类型，并且可以指定多个异常类型。


@Transactional 的使用注意事项总结
1.@Transactional 注解只有作用到 public 方法上事务才生效，不推荐在接口上使用；
2.避免同一个类中调用 @Transactional 注解的方法，这样会导致事务失效；
3.被 @Transactional 注解的方法所在的类必须被 Spring 管理，否则不生效；
4.底层使用的数据库必须支持事务机制，否则不生效；
5.方法中的异常需要抛出;


SpringBoot 自动装配原理详解
1.通过核心注解@SpringBootApplication实现
@SpringBootApplication是由
1@Configuration：允许在上下文中注册额外的 bean 或导入其他配置类
2.@EnableAutoConfiguration：启用 SpringBoot 的自动配置机制
3.@ComponentScan： 扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。

2.@EnableAutoConfiguration:实现自动装配的核心注解,EnableAutoConfiguration 只是一个简单地注解，自动装配核心功能的实现实际是通过 AutoConfigurationImportSelector类
3.AutoConfigurationImportSelector 类实现了 ImportSelector接口，也就实现了这个接口中的 selectImports方法，该方法主要用于获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中。
4.这里我们需要重点关注一下getAutoConfigurationEntry()方法，这个方法主要负责加载自动配置类的。
5.getAutoConfigurationEntry()方法的三个重要步骤:
	1.判断自动装配开关是否打开。默认spring.boot.enableautoconfiguration=true，可在 application.properties 或 application.yml 中设置
	2.用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName
	3.获取需要自动装配的所有配置类，读取META-INF/spring.factories

获取需要自动装配的所有配置类，读取META-INF/spring.factories?
不是,

微服务


Nacos和Eureka的区别
1.CAP理论
C一致性,A高可用,P分区容错性

eureka只支持AP
nacos支持CP和AP两种
nacos是根据配置识别CP或AP模式,如果注册Nacos的client节点注册时是ephemeral=true即为临时节点,那么Naocs集群对这个client节点效果就是AP,反之则是CP,即不是临时节点

 #false为永久实例，true表示临时实例开启，注册为临时实例
 spring.cloud.nacos.discovery.ephemeral=true

2.连接方式
nacos使用的是netty和服务直接进行连接,属于长连接
eureka是使用定时发送和服务进行联系,属于短连接

3.服务异常剔除
eureka:
Eureka client在默认情况每隔30s想Eureka Server发送一次心跳,当Eureka Server在默认连续90s秒的情况下没有收到心跳, 会把Eureka client 从注册表中剔除,在由Eureka-Server 60秒的清除间隔,把Eureka client 给下线
也就是在极端情况下Eureka 服务 从异常到剔除在到完全不接受请求可能需要 30s+90s+60s=3分钟左右(还是未考虑ribbon缓存情况下)

nacos:
nacos client 通过心跳上报方式告诉 nacos注册中心健康状态,默认心跳间隔5秒，
nacos会在超过15秒未收到心跳后将实例设置为不健康状态，可以正常接收到请求
超过30秒nacos将实例删除,不会再接收请求

4.操作实例方式
nacos:提供了nacos console可视化控制话界面,可以对实例列表进行监听,对实例进行上下线,权重的配置,并且config server提供了对服务实例提供配置中心,且可以对配置进行CRUD,版本管理

eureka:仅提供了实例列表,实例的状态,错误信息,相比于nacos过于简单

5.自我保护机制
相同点：保护阈值都是个比例，0-1 范围，表示健康的 instance 占全部instance 的比例。

不同点：

1）保护方式不同

Eureka保护方式：当在短时间内，统计续约失败的比例，如果达到一定阈值，则会触发自我保护的机制，在该机制下，Eureka Server不会剔除任何的微服务，等到正常后，再退出自我保护机制。自我保护开关(eureka.server.enable-self-preservation: false)

Nacos保护方式：当域名健康实例 (Instance) 占总服务实例(Instance) 的比例小于阈值时，无论实例 (Instance) 是否健康，都会将这个实例 (Instance) 返回给客户端。这样做虽然损失了一部分流量，但是保证了集群的剩余健康实例 (Instance) 能正常工作。

2）范围不同
Nacos 的阈值是针对某个具体 Service 的，而不是针对所有服务的。但 Eureka的自我保护阈值是针对所有服务的

Zuul 主要应用场景
1.黑白名单：实现通过IP地址控制禁止访问网关功能，此功能是应用层面控制实现，再往前也可以通过网络传输方面进行控制访问。
2.日志：实现访问日志的记录，可用于分析访问、处理性能指标，同时将分析结果支持其他模块功能应用。
3.协议适配：实现通信协议校验、适配转换的功能。
4.身份认证：负责网关访问身份认证验证，此模块与“访问认证中心”通信，实际认证业务逻辑交移“访问认证中心”处理。
5.计流限流：实现微服务访问流量计算，基于流量计算分析进行限流，可以定义多种限流规则。
6.路由：路由是API网关很核心的模块功能，此模块实现根据请求，锁定目标微服务并将请求进行转发。此模块需要与“服务发布管理中心”通信。“服务发布管理中心”实现微服务发布注册管理功能，与其通信获得目标微服务信息。

 Hystrix能解决什么问题?
 1.服务降级
在高并发情况下，防止用户一直等待（返回一个友好的提示，直接给客户端，不会去处理请求，调用fallBack本地方法），目的是为了用户体验。秒杀----当前请求人数过多，请稍后重试

2.服务熔断
熔断机制目的为了保护服务，在高并发的情况下，如果请求达到一定极限(可以自己设置阔值)如果流量超出了设置阈值，让后直接拒绝访问，保护当前服务。使用服务降级方式返回一个友好提示，服务熔断和服务降级一起使用

3.服务隔离机制
因为默认情况下，只有一个线程池会维护所有的服务接口，如果大量的请求访问同一个接口，达到tomcat 线程池默认极限，可能会导致其他服务无法访问。解决服务雪崩效应:使用服务隔离机制(线程池方式和信号量)，使用线程池方式实現
隔离的原理:
相当于每个接口(服务)都有自己独立的线程池，因为每个线程池互不影响，这样的话就可以解决服务雪崩效应。


Hystrix的设计原理
(1) 防止任何单个依赖项耗尽所有容器用户线程
(2) 减少负载，快速失败，而不是排队
(3) 在失败的情况下提供回退保护用户可用性
(4) 使用隔离技术来限制依赖之间的影响
(5) 通过近乎实时的度量、监视和警报来优化发现时间
(6) 在大多数方面hystrix支持低延迟传播配置和动态属性修改来优化恢复时间，这允许您使用低延迟反馈循环进行实时操作修改
(7) 防止整个依赖客户端执行中的失败，而不仅仅是网络流量中的失败

Hystrix如何实现?
(1) 通过hystrixCommand或者HystrixObservableCommand来封装对外部依赖的访问请求，这个访问请求一般会运行在独立的线程中
(2) 对于超出我们设定的阈值服务调用，直接进行超时返回，不允许它长时间的阻塞
(3) 对每一个依赖服务进行资源隔离。通过线程池或者是semaphore这两种方式
(4) 对依赖服务被调用的成功次数，失败次数，拒绝次数，超时次数进行统计
(5) 如果对某一个依赖服务的调用失败次数超过了一点的阈值，Hystrix自动进行熔断，并在一段时间内对该服务的调用直接进行降级，一段时间后再自动尝试恢复
(6) 当对一个服务调用出现失败、被拒绝、超时、短路等异常情况时，自动调用fallback降级机制
(7) 对属性和配置的修改提供近实时的支持

JVM

线程私有
1.java虚拟机栈；
生命周期与线程相同，虚拟机栈描述的是java方法执行的线程内存模型：每个方法被执行时，java虚拟机都会同步创建一个栈帧用于存储局部变量表，操作数栈，动态连接，方法出口等信息，每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程
2.本地方法栈
本地方法栈是为虚拟机使用到的本地方法服务
3.程序计数器
当前线程所执行的字节码的行号指示器，在java虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支，循环，跳转，异常处理，线程恢复等基础功能都需要依赖这个计数器来完成；

程序计数器为什么是私有的?
在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了.
程序计数器私有主要是为了线程切换后能恢复到正确的执行位置

线程共享
1.java堆
在虚拟机启动时创建，此内存区域唯一的目的就是存放对象实例；
java堆既可以被实现成固定大小的，也可以是扩展的，不过当前主流的java虚拟机都是按照可扩展来实现的，如果java堆中没有内存完成实例分配，并且堆也无法再扩展时，java虚拟机将会抛出outOfMemoryError
2.方法区
用于存储已被虚拟机加载的类型信息，常量，静态变量，即时编译器编译后的代码缓存等数据
	1.运行常量池
	运行常量池是方法区的一部分，class文件中除了有类的版本，字段，方法，接口等描述信息外，还有一项信息是常量池表，用于存放编译器生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中；

对象的创建
1:类加载检查
虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。
2:分配内存
在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。

内存分配的两种方式:
指针碰撞 ： 
	适用场合 ：堆内存规整（即没有内存碎片）的情况下。
	原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。
	使用该分配方式的 GC 收集器：Serial, ParNew
空闲列表 ：
	适用场合 ： 堆内存不规整的情况下。
	原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。
	使用该分配方式的 GC 收集器：CMS
选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"），值得注意的是，复制算法内存也是规整的。

内存分配并发问题
在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：
1.CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。
2.TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配

3:初始化零值
内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

4:设置对象头
初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式

5:执行 init 方法
在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<init> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <init> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。


对象的组成：
1.对象头
	对象头包含两类数据，一类是用于存储对象自身的运行时数据：哈希吗，GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据的长度在32位和64位的虚拟机中分别为32比特和64比特；
	另一部分是类型指针，即对象指向他的类型元数据的指针
2.实例数据
	对象存储的有效信息，即在程序代码里所定义的各种类型的字段内容；
3.对其填充
	起占位符作用

对象的访问定位
1.句柄访问：
	java堆中划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄地址包含了对象实例数据各自具体的地址信息
2.直接指针访问：
	reference存储的就是对象地址
使用句柄地址的好处是reference中存储的就是稳定句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而reference本身不需要被修改；
使用直接指针访问的好处就是速度快，它节省了一次指针定位的开销
java虚拟机使用的是直接指针访问


判断对象是否存活的方法：
1.引用计数器
	在对象中添加一个引用计数器，每当有一个地方引用它时，计数器就加一，当引用失效时就减一，任何时刻计数器为零的对象就是不可能在被使用的；

缺陷-->循环引用：a和b对象相互引用，导致计数器都不为零，也就无法回收；

2.可达性分析-->JAVA内存管理使用的算法
	以根节点为起点，从这些节点开始，根据引用关系向下搜索，搜索过程走过的路径称为引用链，如果某个对象到GC Roots间没有任何引用链相连，就是从根节点到这个对象不可达，则证明此对象是不可能在被使用的

根对象包括一下几种：
	1.在虚拟机栈中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等；
	2.在方法区中静态属性引用的对象，譬如java类引用的类型静态变量；
	3.在方法区中常量引用的对象，譬如字符串常量池里的引用；
	4.在本地方法栈中JNI（Native方法）引用的对象；
	5.所有被同步锁synchronized持有的对象；
	6.反映java虚拟机内部装情况的JMXBean、JVMTI中注册的回调、本地代码缓存等；

引用分为四种：
1.强引用：
	指在程序代码中普遍存在的引用赋值，无论任何情况，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象
2.软引用
	一些还有用，但非必须的对象。只被软引用关联的对象，在系统将要发生内存溢出前，会把这些对象列进回收范围之内进行二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常
3.弱引用
	指非必须对象，它的强度比强引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象
4.虚引用
	它是最弱的一种引用关系，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个实例对象。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知；


判断类是否属于不在被使用的条件：
1.该类的所有实例都已经被回收
2.加载该类的类加载器已经被回收；
3.该类对应的java.lang.Class对象没有在任何地方被引用，无法再任何地方通过反射访问该类的方法；


类的生命周期：
加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）。其中，前三个阶段可以统称为连接（Linking）

1.加载
加载类加载过程的第一步，主要完成下面 3 件事情：
1.通过全类名获取定义此类的二进制字节流。
2.将字节流所代表的静态存储结构转换为方法区的运行时数据结构。
3.在内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口。

2.验证：
验证是连接阶段的第一步，这一阶段的目的是确保 Class 文件的字节流中包含的信息符合《Java 虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。
验证阶段主要由四个检验阶段组成：
1.文件格式验证（Class 文件格式检查）
2.元数据验证（字节码语义检查）
3.字节码验证（程序语义检查）
4.符号引用验证（类的正确性检查）

3.准备
准备阶段是正式为类变量分配内存并设置类变量初始值的阶段

4.解析
解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程

5.初始化
初始化阶段是执行初始化方法 <clinit> ()方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。

6.类卸载
卸载类即该类的 Class 对象被 GC。
所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。
JDK 自带的 BootstrapClassLoader, ExtClassLoader, AppClassLoader 负责加载 JDK 提供的类，所以它们(类加载器的实例)肯定不会被回收

JVM 中内置了三个重要的 ClassLoader：
1.BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要用来加载 JDK 内部的核心类库（ %JAVA_HOME%/lib目录下的 rt.jar 、resources.jar 、charsets.jar等 jar 包和类）以及被 -Xbootclasspath参数指定的路径下的所有类。
2.ExtensionClassLoader(扩展类加载器) ：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类以及被 java.ext.dirs 系统变量所指定的路径下的所有类。
3.AppClassLoader(应用程序类加载器) ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。

除了 BootstrapClassLoader 是 JVM 自身的一部分之外，其他所有的类加载器都是在 JVM 外部实现的，并且全都继承自 ClassLoader抽象类。这样做的好处是用户可以自定义类加载器，以便让应用程序自己决定如何去获取所需的类。
每个 ClassLoader 可以通过getParent()获取其父 ClassLoader，如果获取到 ClassLoader 为null的话，那么该类是通过 BootstrapClassLoader 加载的。

为什么 获取到 ClassLoader 为null就是 BootstrapClassLoader 加载的呢？ 
这是因为BootstrapClassLoader 由 C++ 实现，由于这个 C++ 实现的类加载器在 Java 中是没有与之对应的类的，所以拿到的结果是 null。

双亲委派模型的执行流程：
1.在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载（每个父类加载器都会走一遍这个流程）。
2.类加载器在进行类加载的时候，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成（调用父加载器 loadClass()方法来加载类）。这样的话，所有的请求最终都会传送到顶层的启动类加载器 BootstrapClassLoader 中。
3.只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 findClass() 方法来加载类）。

JVM 判定两个 Java 类是否相同的具体规则 ：
JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。即使两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相同。

双亲委派模型的好处：
双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。

垃圾回收的时机:
1.当Eden分配满的时候触发young GC;
2.在发起young GC之前会统计一下新生代中晋升的对象,如果比老年代的剩余内存大,则直接发起full GC;
  如果老年代在分配担保时内存不足,也会发起full GC;

垃圾收集算法
1.标记-清除算法
	首先标记出所有需要回收的对象，在标记完成后，同一回收掉所有被标记的对象；
缺点：
	1.执行效率不稳定，如果java堆中包含大量对象，，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，呆滞标记和清除两个过程的执行效率都随对象数量增长而降低
	2.空间碎片化，标记清除后会产生大量不连续的内存碎片

2.标记-复制算法
	将内存分为相等的两块，每次只用其中的一块，当这一块内存用完了，就将还存活着的对象复制到另一块。然后再把已使用过的内存空间清除。
	优点：效率高
	缺点：可用空间为原来的一半，浪费空间

3.标记-整理
	根据老年代的特点提出的一种标记算法,让所有存活对象都向内存空间一端移动，然后直接清理掉边界以外的内存；
	缺点：频繁移动对象使回收更复杂

HotSpot 为什么要分为新生代和老年代？
一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。
比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。

垃圾收集器

JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old

1.Serial 收集器
Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ "Stop The World" ），直到它收集结束。
新生代采用标记-复制算法，老年代采用标记-整理算法。

虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。
但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？
当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。

2.ParNew 收集器
ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。
新生代采用标记-复制算法，老年代采用标记-整理算法。

并行和并发概念补充：
并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。

3.Parallel Scavenge 收集器 这是 JDK1.8 默认收集器
Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。
新生代采用标记-复制算法，老年代采用标记-整理算法。
JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old，如果指定了-XX:+UseParallelGC 参数，则默认指定了-XX:+UseParallelOldGC，可以使用-XX:-UseParallelOldGC 来禁用该功能


4.Serial Old 收集器
Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。

5.Parallel Old 收集器
Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。

6.CMS 收集器
CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。
CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。
从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：
1.初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
2.并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
3.重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
4.并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。
从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：
1.对 CPU 资源敏感；
2.无法处理浮动垃圾；
3.它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。

7.G1 收集器
G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.

被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备以下特点：
1.并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
2.分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
3.空间整合：与 CMS 的“标记-清除”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。
4.可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。

G1 收集器的运作大致分为以下几个步骤：

1.初始标记
2.并发标记
3.最终标记
4.筛选回收

G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）


安全点：
	暂停线程执行，开始垃圾收集的点。安全点位置的选取基本上是以“是否具有让程序长时间执行的特征”为标准的
	长时间执行最明显的特征就是指令的复用，例如：方法调用、循环跳转、异常跳转等

安全区域：
	对于进入sleep和blocked的线程，则进入安全区域；
	安全区域是指能确保在某一段代码片段之中，引用关系不会发生改变，因此，在这个区域中任意地方开始垃圾收集都是安全的，可以吧安全区域看做被拉伸的安全点

对象消失问题产生条件（同时满足）：
1.赋值器插入了一条或多条从黑色对象到白色对象的新引用；
2.赋值器删除了全部从灰色对象到该白色对象的直接或间接引用；

解决对象消失问题的两个方法：
1.增量更新：CMS
	增量更新要破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，在将这些记录过的引用关系中的黑色对象为根，重新扫描一次，
结果： 	黑色对象一旦插入了指向白色对象的引用之后，他就变回灰色对象了

2.原始快照：G1，shenandoah
	原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次；
	即无论关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索；
	
衡量垃圾收集器的三个指标:
1.内存占用
2.吞吐量
3.延迟

高效并发
1.如果局部变量是一个Reference类型,它引用的对象在java堆中是线程共享的,但是Reference本身在java栈中的局部变量表中是线程私有的;

2.内存间交互操作
	1.lock-锁定:作用于主内存的变量,它把一个变量标识为一条线程独占的状态;
	2.unlock-解锁:作用于主内存的变量,它把一个处于锁定状态的变量释放出来,释放后的变量才可以被其他线程锁定;
	3.read-读取:作用于主内存的变量,它把一个变量的值从主内存传输到线程的工作内存中,以便随后的load动作使用;
	4.load-载入:作用于主内存的变量,他把read操作从主内存中得到的变量值放入工作内存的变量副本中;
	5.use-使用:作用于主内存的变量,他把工作内存中一个变量的值传递给执行引擎,每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作;
	6.assign-赋值:作用于主内存的变量,它把一个从执行引擎收的值赋给工作内存的变量,每当虚拟机遇到一个变量赋值的字节码指令时就执行这个操作;
	7.store-存储:作用于主内存的变量,他把工作内存中一个变量的值传送到主内存中,以便随后的write操作使用;
	8.write-写入:作用于主内存的变量,他把store操作从工作内存中得到的变量的值放入煮内存的变量中;

	如果要把一个变量从主内存拷贝到工作内存,就要按顺序执行read和load操作,如果要把变量从工作内存同步回主内存,就要按顺序执行store和write操作,
	注意:java内存模型只要求上述两个操作必须按顺序执行,但不要求连续执行
	java内存模型执行上述8种操作时必须满足如下规则:
		1.不允许read和load\store和write操作之一单独出现,即不允许一个变量从主内存读取了但工作内存不接受,或者工作内存发起回写了但主内存不接受的情况出现;
		2.不允许一个线程丢弃它最近的assign操作,即变量在工作内存中改变了之后必须把该变化同步回主内存;
		3.不允许一个线程无原因的把数据从线程的工作内存同步回主内存中;
		4.一个新的变量只能在主内存中诞生,不允许在工作内存中直接使用一个未被初始化(load或assign)的变量,换句话说就是对一个变量实施use\store操作之前,必须限制性assign和load操作;
		5.一个变量在同一时刻只允许一条线程对其进行lock操作,单lock操作可以被同一条线程重复执行多次,多次执行lock后,只有执行相同次数的unlock操作,变量才会被解锁;
		6.如果对一个变量执行lock操作,那将会清空工作内存中此变量的值,在执行引擎使用这个变量前,需要重新执行load或assign操作以初始化变量的值;
		7.如果一个变量事先没有被lock操作锁定,那就不允许对他执行unlock操作,也不允许去unlock一个被其他线程锁定的变量;
		8.对一个变量执行unlock操作之前,必须先把次变量同步回主内存中(执行store\write操作)

volatile:
	特性:
		1.保证此变量对所有线程的可见性,这里的可见性是指当一条线成修改了这个变量的值,新值对于其他线程来说是可以立即得知的
		2.禁止指令重排序优化
	volatile是线程不安全的,因为java里面的运算操作符并非原子操作,这导致volatile变量的运算在并发下一样是不安全的;

	由于volatile变量只能保证可见性,在不符合一下两条规则的运算场景中,我们任然要通过加锁来保证原子性:
	1.运算结果并不依赖变量的当前值,或者能够确保只有单一的线程改变变量的值;
	2.变量不需要与其他的状态变量共同参与不变约束;

原子性-atomicity:
	由java内存模型来直接保证的原子性变量操作包括read,load,assign,use,store,write这六个,基本数据类型的访问读写,都具备原子性;
	如果应用场景需要一个更大范围的原子性保证,java内存模型还提供了lock和unlock操作,synchronized块之间的操作也具备原子性;

可见性-visibility:
	可见性就是指当一个线程修改了共享变量的值时,其他线程能够立即得知这个修改.
	java内存模型是通过在变量修改后将新值同步回主内存,在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的,无论是普通变量还是volatile都是如此.普通变量与volatile变量的区别是,波拉提了的特殊规则保证了新值能立即同步回主内存,以及每次使用前李季从主内存刷新.因此我们可以说volatile保证了多线程操作时变量的可见性,而普通变量则不能保证这一点;
	除了volatile之外,java还有两个关键字能实现可见性,他们是synchronized和final.同步块的可见性是由"对一个变量执行unlock操作之前,必须先把此变量同步回主内存中"这条规则获得的;
	final关键字的可见性是指: 被final修饰的字段在构造器中一旦被初始化完成,并且构造器没有把"this"的引用传递出去,那么在其他线程中就能看见final字段的值.

有序性-ordering:
	如果在本线程内观察,所有的操作都是有序的,如果在一个线程观察另一个线程,所有的操作都是无序的;



导致Java程序CPU与内存冲高的原因主要有以下几种场景：

1.代码中某个位置读取数据量较大，导致系统内存耗尽，从而导致Full GC次数过多，系统缓慢。
2.代码中某个功能，存在死循环或循环产生过多重复的对象实体(因外界数据错误引起的)，集合类中有对对象的引用，使用完后未清空，使得JVM不能回收。导致系统内存耗尽，从而导致Full GC次数过多，系统缓慢。
3.代码中有比较耗CPU的操作(如：算法)，导致CPU过高，系统运行缓慢。
4.代码中某个位置 有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的。
5.某个线程由于某种原因而 进入WAITING状态 ，此时该功能整体不可用，但是无法复现。
6.由于锁使用不当 ，导致多个线程进入死锁状态，从而导致系统整体比较缓慢。

cpu异常排查:
1.jps+top 定位应用进程 pid
2.top -Hp {pid}找到线程 tid
3.将 tid 转换成十六进制 printf “%x\n” {tid}
4.打印堆栈信息 jstack
5.过滤出我们想要的

jvm异常排查:
1.查询gc情况:	jstat -gcutil pid 1000:1
2.jstat命令查看GC信息
3.jmap命令分析内存


top命令查看CPU占用情况
top 查看系统进程CPU与内存占用情况，找到占用最多的进程ID
top -n num 查看CPU占用最高的num个进程
top -Hp PID 或 top -H -p PID查看该进程号的所有线程CPU与内存占用情况，找到占用最多的线程ID


jstack命令查看Java线程信息
jstack 表示生成 Java 虚拟机当前时刻的线程快照
-l 表示长列表（long）
-C10 表示显示关键字所在行前后10行
--color 表示带颜色显示关键字pid

jps -l 显示当前所有 Java 进程ID 的命令 （window环境和linux环境）

printf '%x\n' PID 或 printf %x PID表示将线程ID 转换为十六进制，用于搜索线程堆栈中的关键信息 （linux环境）

jstack PID | grep 线程ID 查看线程堆栈信息 （linux环境）

jstack PID | grep -C10 线程ID --color 查看线程堆栈信息 （linux环境）

jstack -l PID 查看线程堆栈信息

jstack PID >> stack.txt 将当前所有堆栈信息输出到stack.txt文件中

jstat命令查看GC信息
jstat -gcutil PID 1000 2 或 jstat -gc PID 1000 2 表示进程ID每间隔1000毫秒统计2次（缺省代表一直统计），查看某进程GC持续变化情况
gcutil 的意思是[已使用空间]占[总空间]的百分比。

jmap命令分析内存
jmap 是JDK中提供的一个用来监视进程运行中的jvm物理内存的占用情况的工具。
该进程内存中所有对象的情况，例如产生了哪些对象，对象数量。
当系统崩溃时，jmap 可以从core文件或进程中获得内存的具体匹配情况，包括Heap size, Perm size等。

jmap -heap PID 查看进程的JVM占用内存情况
jmap -histo:live PID 显示堆中当前活动的所有对象的统计信息，按实例对象数量从高到低显示。重点关注实例对象数量过多的类。并找到对应程序。
jmap -histo PID | head -n 10 查看前10的对象统计信息
jmap -dump:format=b,file=heap.dump PID 生成堆转储快照dump文件(即：导出堆信息)
format=b 表示输出为二进制;
heap.dump 表示输出的文件名为heap.dump(可指定相对路径或绝对路径);
pid 表示进程ID


Full GC次数过多
1.使用 top 与 top -Hp 命令找到CPU占用最高的Java线程，将其转为16进制后，使用 jstack 命令抓取该线程信息，发现线程名称是"VM Thread" 表示垃圾回收线程。
2.使用 jstat -gcutil 命令查看 GC 次数与增长情况。
3.使用 jmap -dump 命令dump内存，然后使用离线分析，可能是以下两个原因
	1.使用 jmap -dump 命令dump内存，然后使用离线分析，可能是以下两个原因
	2.内存占用不高，但是 Full GC 次数还是比较多，此时可能是代码中手动调用 System.gc 导致 GC 次数过多。

内存溢出:
产生原因：

1.JVM内存过小
2.程序不严谨，产生了过多的垃圾
	一般情况下，在程序上的体现为：

	1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据。
	2.集合类中有对对象的引用，使用完后未清空，使得 JVM 不能回收。
	3.代码中存在死循环或循环产生过多重复的对象实体。
	4.使用的第三方软件中的BUG。
	5.启动参数内存值设定的过小。

解决方法：
1.增加 JVM 的内存大小
2.优化程序，释放垃圾

内存泄露:
产生原因：

在Java中，内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点：
1）首先，这些对象是可达的，即在有向图中，存在通路可以与其相连；
2）其次，这些对象是无用的，即程序以后不会再使用这些对象。
如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。

解决方法：关于内存泄露的处理就是提高程序的健壮型，因为内存泄露是纯代码层面的问题。

总结：内存泄漏的原因分析，总结出来只有一条：存在无效的引用，良好的编码规范以及合理使用设计模式有助于解决此类问题。

1、内存溢出：你申请了10个字节的空间，但是你在这个空间写入11或以上字节的数据，出现溢出。
2、内存泄漏：你用new申请了一块内存，后来很长时间都不再使用了（按理应该释放），但是因为一直被某个或某些实例所持有导致 GC 不能回收，也就是该被释放的对象没有释放。


内存溢出和内存泄露的联系
1.内存泄露会最终会导致内存溢出。
2.相同点：都会导致应用程序运行出现问题，性能下降或挂起。
3.不同点：
	1）内存泄露是导致内存溢出的原因之一，内存泄露积累起来将导致内存溢出。
	2）内存泄露可以通过完善代码来避免。内存溢出可以通过调整配置来减少发生频率，但无法彻底避免。

Java的内存泄露多半是因为对象存在无效的引用，对象得不到释放，如果发现Java应用程序占用的内存出现了泄露的迹象，那么我们一般采用下面的步骤分析：

1.用工具生成java应用程序的heap dump（如 jmap）
2.使用Java heap分析工具（如MAT），找出内存占用超出预期的嫌疑对象
3.根据情况，分析嫌疑对象和其他对象的引用关系。
4.分析程序的源代码，找出嫌疑对象数量过多的原因。

(实际案例：加班单导入日期区间错误，导致内存溢出，服务挂掉；加班单导入，产生大对象, 内存泄露，系统功能响应非常慢)

java程序启动设置参数
-Xmx3550m 堆最大容量(heap max size)
-Xms3550m 堆最小容量(heap min size)
-Xmn2g 年轻代大小
-Xss256k 每个线程栈容量大小(stack size)
-XX:NewRatio=4 年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代），设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5；
-XX:SurvivorRatio=4 年轻代中Eden区与Survivor区的大小比值，设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6
-XX:PermSize=64M 初始分配的永生代容量
-XX:MaxPermSize=128M 永生代最大容量
-XX:MaxTenuringThreshold=0 设置垃圾最大年龄

查看防火墙状态: firewall-cmd --state
开启防火墙:    
start firewalld.service
开启端口（以端口443为例）: firewall-cmd --zone=public --add-port=443/tcp --permanent
重启防火墙: systemctl restart firewalld.service
重新载入防火墙: firewall-cmd --reload
查看已开启的端口: firewall-cmd --list-ports
关闭端口: firewall-cmd --zone=public --remove-port=8080/tcp --permanent

多线程:

创建线程的几种方式:
1.继承于Thread类;
创建一个继承于Thread类的子类,重写Thread类的run() --> 将此线程执行的操作声明在run()中,通过此对象调用start()执行线程
2.实现Runnable接口;
	1.创建一个实现了Runnable接口的类
	2.实现类去实现Runnable中的抽象方法：run()
	3.创建实现类的对象
	4.将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象
	5.通过Thread类的对象调用start()
	① 启动线程
	②调用当前线程的run()–>调用了Runnable类型的target的run()
3.实现Callable接口
	步骤：
	1.创建一个实现Callable的实现类
	2.实现call方法，将此线程需要执行的操作声明在call()中
	3.创建Callable接口实现类的对象
	4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象
	5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()
	6.获取Callable中call方法的返回值
4.使用线程池
	1.以方式二或方式三创建好实现了Runnable接口的类或实现Callable的实现类
	2.实现run或call方法
	3.创建线程池
	4.调用线程池的execute方法执行某个线程，参数是之前实现Runnable或Callable接口的对象


线程的生命周期和状态?
1.NEW: 初始状态，线程被创建出来但没有被调用 start() 。
2.RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。
3.BLOCKED ：阻塞状态，需要等待锁释放。
4.WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
5.TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
6.TERMINATED：终止状态，表示该线程已经运行完毕。


什么是线程池?
线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。

为什么要用线程池？
池化技术想必大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

1.降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
2.提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
3.提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

线程池常见参数有哪些？如何解释？

public ThreadPoolExecutor(int corePoolSize,//线程池的核心线程数量
                              int maximumPoolSize,//线程池的最大线程数
                              long keepAliveTime,//当线程数大于核心线程数时，多余的空闲线程存活的最长时间
                              TimeUnit unit,//时间单位
                              BlockingQueue<Runnable> workQueue,//任务队列，用来储存等待执行任务的队列
                              ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可
                              RejectedExecutionHandler handler//拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务
                               ) 

ThreadPoolExecutor三个重要参数 :
corePoolSize : 任务队列未达到队列容量时，最大可以同时运行的线程数量。
maximumPoolSize : 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
workQueue: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

ThreadPoolExecutor其他常见参数 :
keepAliveTime:线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；
unit : keepAliveTime 参数的时间单位。
threadFactory :executor 创建新线程的时候会用到。
handler :饱和策略。关于饱和策略下面单独介绍一下。

线程池的饱和策略有哪些？
1.ThreadPoolExecutor.AbortPolicy： 抛出 RejectedExecutionException来拒绝新任务的处理。
2.ThreadPoolExecutor.CallerRunsPolicy： 调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
3.ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。
4.ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。

Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略来配置线程池的时候，默认使用的是 AbortPolicy。在这种饱和策略下，如果队列满了，ThreadPoolExecutor 将抛出 RejectedExecutionException 异常来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。如果不想丢弃任务的话，可以使用CallerRunsPolicy。CallerRunsPolicy 和其他的几个策略不同，它既不会抛弃任务，也不会抛出异常，而是将任务回退给调用者，使用调用者的线程来执行任务

线程池常用的阻塞队列有哪些？
不同的线程池会选用不同的阻塞队列，我们可以结合内置线程池来分析。
1.容量为 Integer.MAX_VALUE 的 LinkedBlockingQueue（无界队列）：FixedThreadPool 和 SingleThreadExector 。由于队列永远不会被放满，因此FixedThreadPool最多只能创建核心线程数的线程
2.SynchronousQueue（同步队列）：CachedThreadPool 。SynchronousQueue 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，CachedThreadPool 的最大线程数是 Integer.MAX_VALUE ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。

3.DelayedWorkQueue（延迟阻塞队列）：ScheduledThreadPool 和 SingleThreadScheduledExecutor 。DelayedWorkQueue 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。DelayedWorkQueue 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 Integer.MAX_VALUE，所以最多只能创建核心线程数的线程。

线程池处理任务的流程了解吗？
1.如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。
2.如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到任务队列里等待执行。
3.如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就新建一个线程来执行任务。
4.如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么当前任务会被拒绝，饱和策略会调用RejectedExecutionHandler.rejectedExecution()方法

如何设定线程池的大小？

有一个简单并且适用面比较广的公式：

CPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。

I/O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。


如何判断是 CPU 密集任务还是 IO 密集任务？

CPU 密集型简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。但凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。


什么是上下文切换?
线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。
1.主动让出 CPU，比如调用了 sleep(), wait() 等。
2.时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
3.调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
4.被终止或结束运行

这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 上下文切换。

产生死锁的四个必要条件：
1.互斥条件：该资源任意一个时刻只由一个线程占用。
2.请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3.不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4.循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。

如何预防和避免线程死锁?
 破坏死锁的产生的必要条件即可：
 1.破坏请求与保持条件 ：一次性申请所有的资源
 2.破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源
 3.破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源



sleep()和wait()的区别
1.所属类不同
wait() 是Object中的实例方法
sleep()是Thread的静态方法。

2.唤醒机制不同。
wait() 没有设置最大时间情况下，必须等待对象调用notify() 或notifyAll()方法。
sleep是到指定时间自动唤醒。

3.锁机制不同。
wait()释放锁，调用对象的wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进

sleep()只是让线程休眠，让出cpu资源，不会释放锁,当休眠时间结束后，线程会恢复到就绪状态，但是不会立刻执行，可能会有其他优先级高的线程抢占资源。
4.使用位置不同。
wait()必须持有对象锁，写在同步方法或者synchronized()语句块中。
sleep()可以使用在任意地方。

5.sleep()必须捕获异常
wait()，notify()和notifyAll()不需要捕获异常。


为什么 wait() 方法不定义在 Thread 中?
wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）

可以直接调用 Thread 类的 run 方法吗？
new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。
调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。

什么是悲观锁？使用场景是什么？
悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。像 Java 中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

悲观锁通常多用于写多比较多的情况下（多写场景），避免频繁失败和重试影响性能。

synchronized 和 volatile 有什么区别？
1.volatile 关键字是线程同步的轻量级实现，所以 volatile性能肯定比synchronized关键字要好 。但是 volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块 
2.volatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。
3.volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。

自旋锁缺点
1.第一个是锁饥饿问题。在锁竞争激烈的情况下，可能存在一个线程一直被其他线程”插队“而一直获取不到锁的情况。
2.第二是性能问题。在实际的多处理上运行的自旋锁在锁竞争激烈时性能较差。


CLH 优缺点分析
CLH 锁作为自旋锁的改进，有以下几个优点：
1.性能优异，获取和释放锁开销小。CLH 的锁状态不再是单一的原子变量，而是分散在每个节点的状态中，降低了自旋锁在竞争激烈时频繁同步的开销。在释放锁的开销也因为不需要使用 CAS 指令而降低了。
2.公平锁。先入队的线程会先得到锁。
3.实现简单，易于理解。
4.扩展性强。下面会提到 AQS 如何扩展 CLH 锁实现了 j.u.c 包下各类丰富的同步器。

缺点:
1.第一是因为有自旋操作，当锁持有时间长时会带来较大的 CPU 开销。
2.第二是基本的 CLH 锁功能单一，不改造不能支持复杂的功能。


AQS 对 CLH 队列锁的改造

针对 CLH 的缺点，AQS 对 CLH 队列锁进行了一定的改造。针对第一个缺点，AQS 将自旋操作改为阻塞线程操作。针对第二个缺点，AQS 对 CLH 锁进行改造和扩展，原作者 Doug Lea 称之为“CLH 锁的变体”。下面将详细讲 AQS 底层细节以及对 CLH 锁的改进。AQS 中的对 CLH 锁数据结构的改进主要包括三方面：扩展每个节点的状态、显式的维护前驱节点和后继节点以及诸如出队节点显式设为 null 等辅助 GC 的优化。正是这些改进使 AQS 可以支撑 j.u.c 丰富多彩的同步器实现。

公平锁和非公平锁有什么区别？

公平锁 : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
非公平锁 ：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁

ReentrantLock 默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。

可中断锁和不可中断锁有什么区别？
可中断锁 ：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。ReentrantLock 就属于是可中断锁。
不可中断锁 ：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 synchronized 就属于是不可中断锁。


线程持有读锁还能获取写锁吗？
1.在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。
2.在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）;

读锁为什么不能升级为写锁？
1.写锁可以降级为读锁，但是读锁却不能升级为写锁。这 是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。
2.可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。




上下文切换：
多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。
上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少



mybatis

工作流程总结

*
* 总结：
* 1、根据配置文件（全局，sql映射）初始化出Configuration对象
* 2、创建一个DefaultSqlSession对象，他里面包含Configuration以及Executor（根据全局配置文件中的defaultExecutorType创建出对应的Executor）
* 3、DefaultSqlSession.getMapper（）：拿到Mapper接口对应的MapperProxy；
* 4、MapperProxy里面有（DefaultSqlSession）；
* 5、执行增删改查方法：
* 1）、调用DefaultSqlSession的增删改查（Executor）；
* 2）、会创建一个StatementHandler对象。
* （同时也会创建出ParameterHandler和ResultSetHandler）
* 3）、调用StatementHandler预编译参数以及设置参数值;
* 使用ParameterHandler来给sql设置参数
* 4）、调用StatementHandler的增删改查方法；
* 5）、ResultSetHandler封装结果

Seata 定义了 3 个核心组件：
TC（Transaction Coordinator）：事务协调器，它是事务的协调者（这里指的是 Seata 服务器），主要负责维护全局事务和分支事务的状态，驱动全局事务提交或回滚。
TM（Transaction Manager）：事务管理器，它是事务的发起者，负责定义全局事务的范围，并根据 TC 维护的全局事务和分支事务状态，做出开始事务、提交事务、回滚事务的决议。
RM（Resource Manager）：资源管理器，它是资源的管理者（这里可以将其理解为各服务使用的数据库）。它负责管理分支事务上的资源，向 TC 注册分支事务，汇报分支事务状态，驱动分支事务的提交或回滚。

Seata 的整体工作流程如下：AT模式
1.TM 向 TC 申请开启一个全局事务，全局事务创建成功后，TC 会针对这个全局事务生成一个全局唯一的 XID；
2.XID 通过服务的调用链传递到其他服务;
3.RM 向 TC 注册一个分支事务，并将其纳入 XID 对应全局事务的管辖；
4.TM 根据 TC 收集的各个分支事务的执行结果，向 TC 发起全局事务提交或回滚决议；
5.TC 调度 XID 下管辖的所有分支事务完成提交或回滚操作。

Seata 提供了 AT、TCC、SAGA 和 XA 四种事务模式，可以快速有效地对分布式事务进行控制。

在这四种事务模式中使用最多，最方便的就是 AT 模式。与其他事务模式相比，AT 模式可以应对大多数的业务场景，且基本可以做到无业务入侵，开发人员能够有更多的精力关注于业务逻辑开发。

jdk命令:
1.jps 虚拟机进程状况
2.jstat	 虚拟机统计信息监视工具
3.jinfo  java配置信息工具
4.jmap  java内存映像工具
5.jstack  java堆栈跟踪工具



Kafka的特性：
1.高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒
2.可扩展性：kafka集群支持热扩展
3.持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
4.容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
5.高并发：支持数千个客户端同时读写

Kafka场景应用：
1.日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等
2.消息系统：解耦和生产者和消费者、缓存消息等。
3.用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
4.运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
5.流式处理：比如spark streaming和storm

如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？
1.partition在写入的时候可以指定需要写入的partition，如果有指定，则写入对应的partition。
2.如果没有指定partition，但是设置了数据的key，则会根据key的值hash出一个partition。
3.如果既没指定partition，又没有设置key，则会轮询选出一个partition

producer在向kafka写入消息的时候，怎么保证消息不丢失呢？
生产者:
通过ACK应答机制，在生产者向队列写入数据的时候可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为0、1、all。
0代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。
1代表producer往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功。默认
all代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。
将ack设置为1
生产者将数据添加到队列后再添加回调，保证消息不丢失；
消费者:
将enable-auto-commit设置为FALSE（手动提交），
ack.acknowledge();（手动提交）

重发问题:
使用Redis幂等性,每个消息都添加一个id,消费者获取消息后检查一下id是否重复,重复就丢弃,未重复就消费,然后将id添加到缓存;

如果往不存在的topic写数据，能不能写入成功呢？
kafka会自动创建topic，分区和副本的数量根据默认配置都是1。

kafka如何提高服务端吞吐量?
num.network.threads: 负责转发请求给实际工作线程的网络请求处理线程的数量,默认情况是3,高负载场景下可以设置大一点;
num.io.threads: 实际处理请求的线程数量,默认是8,高负载场景下可以设置大一点;


Git 基本指令的使用
下面介绍一下git中常用的几种命令：

git config：配置信息
git add：添加文件到缓存命令
git status：查看文件的状态命令
git diff：查看更新的详细信息命令
git commit：提交命令
git reset HEAD：取消缓存命令
git rm：删除命令
git mv：移动或重命名命令
git remote add：添加远程仓库
git remote：查看当前的远程仓库
git fetch、git pull：提取远程仓仓库
git push：推送到远程仓库
git remote rm：删除远程仓库



单例双重锁

public class SingletonExample {
    private volatile static SingletonExample singletonExample;
    public SingletonExample getInstance(){
        if (singletonExample==null){
            synchronized (SingletonExample.class){
                if (singletonExample==null){
                    singletonExample=new SingletonExample();
                }
            }
        }
        return singletonExample;
    }
}

如果这样写，运行顺序就成了：

1.检查变量是否被初始化(不去获得锁)，如果已被初始化则立即返回。
2.否则获取锁。
3.再次检查变量是否已经被初始化，如果还没被初始化就初始化一个对象。

执行双重检查是因为，如果多个线程同时了通过了第一次检查，并且其中一个线程首先通过了第二次检查并实例化了对象，那么剩余通过了第一次检查的线程就不会再去实例化对象。
这样，除了初始化的时候会出现加锁的情况，后续的所有调用都会避免加锁而直接返回，解决了性能消耗的问题。



隐患
重排序造成的隐患

上述写法看似解决了问题，但是有个很大的隐患。实例化对象的那行代码（标记为error的那行），实际上可以分解成以下三个步骤：

1.分配内存空间
2.初始化对象
3.将对象指向刚分配的内存空间

但是有些编译器为了性能的原因，可能会将第二步和第三步进行重排序，顺序就成了：

1.分配内存空间
2.将对象指向刚分配的内存空间
3.初始化对象



IP地址:
	1.标示地址
	2.表示设备
NAT:网络地址转换
	1.实现内部网络与外部网络通信,通过nat可以将私网地址转换为公网地址,多个私网地址可以共用一个公网地址;89O0-

网络模型:
1.物理层 mac
2.数据链路层 
3.网络层 IP,ARP,nat
4.传输层 tcp/udp
5.会话层 
6.表示层 tls/ssl
7.应用层 http

对称加密: 只有一个公钥,加密和解密算法相同
非对称加密: 有公钥和私钥
			公钥加密,私钥解密
			私钥加密,公钥解密

对称非对称混合加密:
1.服务端将非对称公钥发送给客户端
1.客户端将随机数使用公钥加密发送给服务端
2.服务端解密出随机数,

tls握手过程
1.client发送clientHello,包含所支持的tls版本,随机数,支持的加密算法
2.server发送serverHello,包含服务器选择的tls版本,随机数,选择的加密算法
3.server发送Certificate,包含服务器证书信息
4.server发送ServerKeyExchange,包含算法参数
5.server发送ServerHelloDone,告诉客户端客户端握手信息发送完毕
6.client发送clientkeyExchange,包含preMasterSecret,preMasterSecret是通过证书中的puk生成的加密数据
7.client和server通过client,server发送的随机数+preMasterSecret生成对称公钥masterSecret
8.client发送changeCipherSpec记录,告诉server后面发送的数据都是加密数据了
9.clinet发送已验证的finished,包含对之前数据的hash和mac
10.server接收client发送的finished,进行解密并且验签,如果解密和验签失败,则握手失败
11.server发送changeCipherspec记录,告诉client后面发送的数据都是加密数据
12.server发送已验证且加密的finished消息,包含对之前消息的hash和mac
13.client对server发送的finished解密和验签,如果解密验签失败,则握手失败






cpu异常排查
https://blog.csdn.net/weixin_40682142/article/details/88295682
jvm监控及问题排查
https://blog.csdn.net/chinabestchina/article/details/93615698
Java线上性能问题-排查方法汇总
https://blog.csdn.net/huangliangbao2009/article/details/129738200?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-129738200-blog-117416355.235%5Ev36%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-129738200-blog-117416355.235%5Ev36%5Epc_relevant_default_base3&utm_relevant_index=8

Mysql的事务实现原理
https://zhuanlan.zhihu.com/p/117452178
MVCC详解
https://blog.csdn.net/lans_g/article/details/124232192
海量数据分库分表方案
https://zhuanlan.zhihu.com/p/137644085
数据库分库分表后”跨库分页“查询方案
https://blog.csdn.net/uiuan00/article/details/102716457
Hash一致性算法是如何解决数据倾斜问题的
https://blog.csdn.net/weixin_42864905/article/details/105635577

深入浅出系列-分布式事务Seata AT模式
https://zhuanlan.zhihu.com/p/618914697
Kafka为什么吞吐量大、速度快？
https://zhuanlan.zhihu.com/p/120967989
Kafka分片存储、消息分发和持久化机制
https://www.cnblogs.com/wusier/p/14648955.html
Redis的两种持久化方式
https://zhuanlan.zhihu.com/p/345725544

java中的Lock锁
https://blog.csdn.net/xyy1028/article/details/107333451

Java反射
https://blog.csdn.net/qq_44715943/article/details/120587716

Java动态代理-最通俗易懂的动态代理
https://www.bilibili.com/video/BV1n3411Q71b/?p=2&spm_id_from=pageDriver&vd_source=310ea727a0db57a9d10d98f235ff8b6f

大彻大悟synchronized原理，锁如何升级
https://zhuanlan.zhihu.com/p/290991898

生产环境JVM优化以及问题排查
https://www.bilibili.com/video/BV1VB4y1R7Kh/?spm_id_from=333.337.search-card.all.click&vd_source=310ea727a0db57a9d10d98f235ff8b6f

Redis 底层原理实现
https://www.bilibili.com/video/BV1wT4y1u7iF/?p=5&spm_id_from=pageDriver&vd_source=310ea727a0db57a9d10d98f235ff8b6f


Synchronized原理 锁升级过程
https://www.bilibili.com/video/BV1K34y1j7ZN/?spm_id_from=pageDriver&vd_source=310ea727a0db57a9d10d98f235ff8b6f

亿级数据分库分表查询相关问题
https://www.bilibili.com/video/BV1Lt4y1N73q/?spm_id_from=autoNext&vd_source=310ea727a0db57a9d10d98f235ff8b6f


spring 循环依赖以及解决方案
https://blog.csdn.net/wangxuelei036/article/details/104960558

Spring源码合集
https://www.bilibili.com/video/BV1qL411g7D2/?spm_id_from=333.337.search-card.all.click&vd_source=310ea727a0db57a9d10d98f235ff8b6f

 MySQL原理
 https://www.bilibili.com/video/BV1He4y177fa/?p=5&spm_id_from=pageDriver&vd_source=310ea727a0db57a9d10d98f235ff8b6f



 1.spring和springboot的区别?
 	1.springboot的pom文件集成了start依赖,更加方便的引入依赖
 	2.springboot使用去除了xml的装配配置,使用自动装配扫描依赖的spring.factory文件中的配置类
 2.springboot的注解有哪些?
 	springbootapplication
 	springbootconfigration
 	springbootbanner
 3.springboot的自动装配原理?
 springbootapplication包含springbootconfigration,compoentspcan,EnableAutoConfiguration,其中enableautoconfiguration注解包含了autoconfigutationImportSelector类,autoconfigurationImportSelect类实现了importSelect接口,重写了selectImport方法,在这个方法中会扫描依赖的spring.factory文件中的配置类加载到spring容器中
 4.bean的生命周期
 	1.创建bean对象
 	2.set注入bean属性
 	3.如果有实现后置处理器的before方法,就执行before方法
 	4.初始化对象
 	5.如果有实现后置处理器的after方法,就执行after方法
 	6.使用bean
 	6.销毁bean对象
 5.spring的ioc
 	将创建对象的权利交给spring,由spring管理对象的创建销毁
 6.aop的原理?使用场景?使用方式?
 	aop是通过动态代理实现的,在spring加载bean对象时,如果使用了aop,会在后置处理器的after方法添加责任链;
 	使用场景一般在日志打印,统一异常处理,
 	使用注解@pointcut添加在切点方法上
 	然后在需要切面的方法上添加@before或@after,@AfterReturning方法返回后调用,@AfterThrowing目标方法抛出异常时调用
 5.spring循环依赖和三级缓存
 	bean1和bean2有相互依赖时会产生循环依赖,使用三级缓存可以解决set注入的循环依赖,
 	三级缓存是解决循环依赖的方式,已创建完成的bean对象会放入一级缓存,二级缓存放的是半成品的bean对象,三级缓存存放的是生成bean对象的factory,当bean1对象创建时,发现有依赖bean2对象,会将bean1对象放入三级缓存,再去创建bean2对象,创建出bean2对象后,发现需要注入bean1对象,会先去一级缓存检查是否存在,如果不存在就去二级缓存查找,还没找到就去三级缓存查找,如果在三级缓存找到bean1对象的工厂, 就获取bean1对象,将bean1对象放入二级缓存同时删除三级缓存的对象,当bean2对象创建完成后放入一级缓存,再创建bean1对象,从一级缓存获取bean2对象依赖
 6.单例bean的双重锁机制
 	使用volatile和synchronize实现
 7.mybatis的原理?
 	1.spring启动时加在yml文件的资源,生成configuration配置类
 	2.通过DefaultSqlSessionFactorybuilder.build创建defaultsqlsessionfactory
 	3.通过sqlSessionFactory.openSession()创建sqlsession,开启一次会话
 	4.sqlsession.getMapper()获取mapper代理对象
 	5.调用mapper方法,交由executor执行器执行具体方法
 	6.executor会通过MappedStatement执行boundSQL,再通过resultstatement封装结果
 8.mybatis的主要标签有哪些?
 	crud,cache,resultmap,parammap
 9.mybatis的事务,实现原理?
 	@Transactional,通过动态代理生成代理类,执行代理方法,在异常抛出时执行增强方法
 10.mybatis事务失效的场景及原因?
 	1.对象没交给spring管理
 	2.数据库不支持事务
 	3.对象内部调用方法
 	4.未使用public方法
 	5.方法异常未抛出
 11.mybatis事务的传播方式
 	1.              
 12.mysql的索引是什么?
 b+树
 13.b树和b+树的区别?
 	1.b树的节点是唯一的,b+树的节点是可重复的
 	2.b树所有节点都存放数据,b+树只有叶子结点存放数据
 	3.b+树的页子节点的头尾部有双向指针
 14.辅助索引和主键索引?
 	辅助索引是非聚簇索引实现的,主键索引是聚簇索引实现的
 15.mysql索引优化
 	1.主键索引使用自增字段
 	2.创建辅助索引是需要考虑字段是否有序,是否常用,是否选择性高
 	3.如果索引长度过长,可以考虑使用前缀索引或后缀索引
 16.聚簇索引和非聚簇索引的区别?
 	聚簇索引的叶子结点放的是行数据,非聚簇索引放的数据的地址
 17.什么是回表?
 	通过辅助索引查询时,先查询到主键的值,再通过主键值去主键索引树查询行数据
 18.索引下推和索引覆盖?
 	索引下推是如果通过组合索引查询数据,会在辅助索引查询时就过滤所有组合索引的条件,减少回表次数
 19.索引失效的场景及原因?
 	1.隐式转换
 	2.查询索引的条件使用函数或计算逻辑
 	3.使用or或like 左%
 	4.查询的条件选择性低
 	5.未使用最左原则
 20.分库分表,hash一致性?
 	使用hash环,将取模字段hash后散列在环上,可以添加虚拟节点使真实节点散步更均匀
 21.慢sql分析
 	1.检查表数据是否过多
 	2.检查SQL是否关联表较多
 	3.检查是否使用到索引字段
 	4.查询的字段和数据是否有非必要的
 22.事务的实现原理
 	通过mvcc实现
 23.mvcc原理
 	mvcc通 v隐藏字段db_txd_id和undolog实现,开启事务时会生成一个readview快照放入undolog,快照包含数据和txd_ids当前活跃事务列表,up_txd_id活跃事务列表最小的txd_id值,low_txd_id下一事务id值,事务SQL查询数据时,如果表数据的txd_id小于up_txd_id就能看到,如果在up_txd_id和low_txd_id之间,就看txd_id是否在txd_ids中,不在就能看到,在就表示修改表数据的事务未结束,不能看到.
 24.mysql的锁机制
 	间隙锁,记录锁
 25.悲观锁和乐观锁
 	乐观锁是通过版本号机制实现,每次修改数据的时候对比一下版本号,版本号一致就可以修改
 26.Explain执行计划的主要字段说明
 	type:访问类型,从最好到最差的连接类型为const、eq_reg、ref、range、indexhe和ALL,一般来说，好的sql查询至少达到range级别，最好能达到ref
 	key:查询的索引字段
 	key_len:索引字段长度
 	rows:大概读取的行数
 27.Redis的应用场景
 	缓存热点数据,分布式锁
 28.Redis的主要字段类型
 	string,list,hash,set,zset
 29.缓存击穿和缓存雪崩
 30.Redis持久化方式和区别
 	rdb:数据快照方式,有丢数据的风险
 	aof:执行过程的存储,效率低
 31.Redis为什么是线程安全的?
 	处理数据的线程是单线程
 32.Redis使用分布式锁的方式?
  setnx,0就是已有数据,1就是成功
 33.kafka使用场景?
 	削峰
 	消息订阅
 	异步处理
 34.kafka和mq的区别?
 	1.kafka的吞吐量更大
 	2.kafka不支持消费失败重试offset存储在broker中,mq支持offset存储在broker中
 	3.kafka主节点失效后支持自动切换,mq不支持
 35.kafka的原理?分区/分组/备份
 36.kafka为什么吞吐量大?
 	1.批量发送和拉取
 	2.使用系统内存缓存数据
 	3.在磁盘持久化数据使用顺序写
 	4.零拷贝机制
 37.kafka如何提高消费端吞吐量?
 	1.添加消费者数量
 	2.消费端使用多线程消费
 38.kafka如何提高服务端吞吐量?
 	1.将接收请求的线程数据增加,默认是3,num.network.threads
 	2.将处理消息的线程增加,默认是8,num.io.threads
 39.kafka的消息丢失和消息重复问题?
 	消息丢失:
 		 将ack机制设置为1,同时获取发送回调结果,发送失败重新发送
 		 消费端改为手动提交offset,消费完消息后在提交
 	消息重复:
 		使用Redis或mysql幂等性
 40.使用Redis很费mysql解决kafka消息重复问题为什么使用Redis?Redis快
 41.kafka的持久化方式?极少问
 	存储在磁盘内,生成log文件
 42.kafka索引?极少问
 	kafka索引使用的是稀松索引,kafka每存储4kb数据就在索引文件插入offset和position物理位置
 43.你们业务kafka的吞吐量
 	每天30w
 44.kafka多分区会产生什么问题?同一主题数据在不同分区不是顺序的
 	kafka默认是轮训发送数据到每个分区,分区的数据不是顺序的,想要按顺序消费,可以在生产端指定key值
 45.springcloud有哪些主要组件?
 	zuul网关,eureka注册中心,hystrix熔断器,fening通信
 46.网关使用的哪个?zuul,网关使用的哪些场景
 	1.限流分流
 	2.黑白名单
 	3.权限验证
 	4.路由
 47.注册中心使用的哪个?Nacos和Eureka的区别
 	eurake
 	1.nacos相比eureka性能更高
 	2.eureka只支持ap,nacos支持ap和ap
 	3.nacos使用netty和服务连接,属于长连接,eureka使用轮训查询,是短连接
 	4.nacos有可视化操作界面,支持东台更新配置
 48.Hystrix的原理?及使用方式?服务降级和熔断,熔断时长
 	1.hystrix通过hystrixcommond包装对服务的请求,每一次请求都是一个独立的线程
 	2.hystrix对每个服务都有一个单独的线程池,默认是10个线程,实现服务隔离
 	3.每次请求都会记录成功次数,失败次数,超时次数,如果超过设定的阈值,就会熔断并且服务降级,默认是10秒内50%,或10秒内请求失败,超时20次
 	4.当服务熔断时会请求会直接返回fallback的信息
 	在配置文件设置超时时间,并且实现feign接口,在启动类上添加@EnableHystrix
 49.jvm的主要内存区域
 	java虚拟机栈,
 	本地方法栈
 	线程计数器
 	堆
 	方法区
 50.栈帧的组成?jvm调用方法的流程
 	栈帧包含:局部变量表,操作数栈,方法出口,动态连接
 	jvm每调用一个方法就会生成一个对应的栈帧,栈帧有着先进后出的原则
 51.jvm垃圾回收过程,垃圾回收算法
 	当创建对象时,edan区的内存不足时,jvm发起yanggc,回收新生代
 	当新生代晋升老年代对象大小超过老年代剩余内存时,或分配担保内存不足时,发起fullgc,回收整个堆和方法区
 52.对象创建的内存分配
 	对象会先出生edan区,如果是大对象或数组直接放入老年代
 53.jvm内存溢出排查流程?及linux命令
 	1.jstat -gcutil 查询gc信息
 	2.jmap -dump:format=b,file=heap.dump PID 下载dump文件查询对象信息
 54.cpu飙升异常排查?及linux命令
 	1.jps 和top查询进程信息
 	2.top -hp pid 查询线程
 	3.printf %x 将线程转为16进制
 	4. jstack PID >> stack.txt 打印堆栈信息

 55.生产环境异常排查流程
 56.ArrayList的扩容
 57.hashmap和hashtable的区别
 58.hashmap和concurrenthashmap的区别?concurrenthashmap为什么是线程安全的
 59.线程的创建方式?
 60.为什么使用线程池
 61.线程池执行的两种方式及区别
 62.cap理论?seata
 	c一致性
 	a高可用
 	p分区容错性
 63.synchronized锁升级过程
 64.synchronized和lock的区别
 65.ReentrantLock的原理
 66.网络模型,tcp和udp,tcp和http
 67.https
68.消息队列的优点和缺点
有点:削峰,异步,解耦
缺点:系统复杂性提高,系统稳定性降低,一致性问题
69.消息队列为什么是可靠的
  1.消息持久化
  2.生产者和消费者有应答机制
  3.消费失败可重发
  4.幂等性
